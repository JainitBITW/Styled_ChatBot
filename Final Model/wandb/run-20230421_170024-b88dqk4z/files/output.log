9317
training ....
  0%|                                                                                                                                                                                                     | 0/10 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                     | 0/10 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/hardk/AMNESIA/College/Sem 4/NLP/Project/Jainit Repo/Styled_ChatBot/Final Model/main.py", line 191, in <module>
    train(chatData, model, optim, int(NUM_EPOCHS))
  File "/home/hardk/AMNESIA/College/Sem 4/NLP/Project/Jainit Repo/Styled_ChatBot/Final Model/main.py", line 77, in train
    optim.step()
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 162, in step
    adamw(params_with_grad,
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 219, in adamw
    func(params,
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 316, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/hardk/AMNESIA/College/Sem 4/NLP/Project/Jainit Repo/Styled_ChatBot/Final Model/main.py", line 191, in <module>
    train(chatData, model, optim, int(NUM_EPOCHS))
  File "/home/hardk/AMNESIA/College/Sem 4/NLP/Project/Jainit Repo/Styled_ChatBot/Final Model/main.py", line 77, in train
    optim.step()
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 162, in step
    adamw(params_with_grad,
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 219, in adamw
    func(params,
  File "/home/hardk/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 316, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt